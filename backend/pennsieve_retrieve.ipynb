{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fd6d48-95f9-4d1f-bc8c-f3c4d2759a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import .env variables\n",
    "# from dotenv import dotenv_values\n",
    "# config = dotenv_values(\".env\")\n",
    "# config[\"USERNAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ab5b93-eb0e-4b82-b412-7e3ef1fb7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import boto3\n",
    "import requests\n",
    "import pandas as pd \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90470ed-00d1-4683-b47f-d7a4930bab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def authenticate_user():\n",
    "#     PENNSIEVE_URL = \"https://api.pennsieve.io\"\n",
    "#     email = config[\"USERNAME\"]\n",
    "#     password = config[\"PASSWORD\"]\n",
    "\n",
    "#     r = requests.get(f\"{PENNSIEVE_URL}/authentication/cognito-config\")\n",
    "#     r.raise_for_status()\n",
    "#     cognito_app_client_id = r.json()[\"userPool\"][\"appClientId\"]\n",
    "#     cognito_region = r.json()[\"userPool\"][\"region\"]\n",
    "\n",
    "#     cognito_client = boto3.client(\n",
    "#     \"cognito-idp\",\n",
    "#     region_name=cognito_region,\n",
    "#     aws_access_key_id=\"\",\n",
    "#     aws_secret_access_key=\"\")\n",
    "    \n",
    "#     login_response = cognito_client.initiate_auth(\n",
    "#     AuthFlow=\"USER_PASSWORD_AUTH\",\n",
    "#     AuthParameters={\"USERNAME\": email, \"PASSWORD\": password},\n",
    "#     ClientId=cognito_app_client_id)\n",
    "    \n",
    "#     api_key = login_response[\"AuthenticationResult\"][\"AccessToken\"]\n",
    "    \n",
    "#     r = requests.get(f\"{PENNSIEVE_URL}/user\", headers={\"Authorization\": f\"Bearer {api_key}\"})\n",
    "#     r.raise_for_status()\n",
    "#     print(r.json())\n",
    "#     return api_key \n",
    "    \n",
    "# api_key = authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22c1598-216a-438e-a8e5-fcb22d9f8808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [00:35<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_published_datasets():\n",
    "    url = \"https://api.pennsieve.io/discover/search/records\"\n",
    "    querystring = {\"model\": \"award\"}\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    response.raise_for_status()\n",
    "    response = response.json()\n",
    "    querystring = {\"limit\": response[\"totalCount\"], \"model\": \"award\"}\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    response = response.json()\n",
    "    list_of_datasets = response[\"records\"].copy()\n",
    "    return list_of_datasets\n",
    "\n",
    "list_of_datasets = get_published_datasets()\n",
    "list_of_datasets[0]\n",
    "\n",
    "for item in tqdm(list_of_datasets):\n",
    "    url = f\"https://api.pennsieve.io/discover/datasets/{item['datasetId']}\"\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    response = response.json()\n",
    "    item['version'] = response['version']\n",
    "    item['versionPublishedAt'] = response['versionPublishedAt']\n",
    "    item['datasetDOI'] = 'https://dx.doi.org/' + response['doi']\n",
    "    item['tags'] = response['tags']\n",
    "    item['contributors'] = response['contributors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c130c0-21c8-4679-b845-9eb4798346cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change loop variant on prod\n",
    "# for item in list_of_datasets[:1]:\n",
    "#     url = f\"https://api.pennsieve.io/discover/datasets/{item['datasetId']}/versions/{item['version']}/files\"\n",
    "#     querystring = {\"path\":\"files/dataset_description.xlsx\"}\n",
    "#     headers = {\"Accept\": \"application/json\"}\n",
    "#     response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "#     response = response.json()\n",
    "#     item[\"datasetDescriptionPackageId\"] = response[\"sourcePackageId\"]\n",
    "#     print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63265008-c79c-4593-ae70-235a0408668a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasetId': 35, 'version': 3, 'model': 'award', 'properties': {'description': 'PROJECT ABSTRACTThe peripheral and central elements of the respiratory control system are not “fixed,” but undergo sustained(neuroplastic) circuit reorganization to optimize function. This system can selectively utilize unique afferentmodalities and brainstem neural pathways to elicit episodic, coordinated airway protective behaviors (e.g.cough, laryngeal adduction). Neuroplasticity is induced and undermined by inflammation, transient afferentfeedback, or CNS injury. As a result, breathing responses and airway protective behaviors are altered in waysthat can be adaptive or maladaptive. Existing models of the brainstem network and sensory control systemregulating breathing and airway protection do not explain changes in responses caused by neuroplasticity insensory, central integrating and efferent motor elements of the control system. This knowledge gap concerningperipheral and central circuit-based processes increases the risk of inappropriate depression in breathing orairway protective mechanisms by the neuromodulatory approaches being investigated in the SPARC initiative.In this project, our goal is to understand fundamental principles of modulation and plasticity in afferentpathways, brain networks and efferent systems controlling breathing and airway defense. The proposedresearch will advance our understanding of circuits underlying respiratory control, laying the foundation forfuture neuromodulatory strategies to normalize lung function in vulnerable clinical populations. We haveassembled a multidisciplinary team to utilize cutting edge genetic, neuroanatomical, neurophysiological andcomputational modeling approaches to interrogate sensory, central and motor pathways of the respiratorycontrol system. Complementary studies will be performed in human patient populations with various forms ofsensory or motor dysfunction, including those with laryngectomy, double lung transplants and unilateral vocalfold paralysis. Through these parallel studies, we will reveal fundamental mechanisms of respiratoryneuroplasticity resulting from injury, disease and/or afferent activation. New knowledge from peripheral andcentral circuits in animal models and humans with pathologies will be used to create an iterative, computationalneuromechanical model that incorporates key elements of neuroplasticity. This model will enable predictionsas we develop neuromodulatory approaches to inform novel treatments for respiratory dysfunction. The projectis separated into four encompassing aims. Aim 1: Identify neuroanatomical and functional plasticity of lungsensory mechanisms that regulate brainstem pathways for airway protective reflexes. Aim 2: Identify shorttime-scale and sustained, circuit-based plasticity in airway motor, brainstem and spinal respiratory motorpathways induced by sensory feedback (airway and diaphragm) and/or injury/disease. Aim 3: Investigate keyfeatures of neuroplasticity in human respiratory behaviors. Aim 4: Develop a neuromechanical computationalmodel of the neural system controlling breathing and airway defense that incorporates plasticity induced bysensory afferent feedback and injury/disease.', 'id': '4f204d87-08db-4790-a1ee-e2ee389dcb64', 'principal_investigator': 'BOLSER, DONALD C', 'title': 'FUNCTIONAL MAPPING OF PERIPHERAL AND CENTRAL CIRCUITS FOR AIRWAY PROTECTION AND BREATHING', 'award_id': 'OT2OD023854'}, 'versionPublishedAt': '2020-03-02T20:37:45.459724Z', 'datasetDOI': 'https://dx.doi.org/10.26275/1upo-xvkt', 'tags': ['blood pressure', 'respiration', 'hypoglossal', 'neural circuits', 'swallow', 'expired co2', 'superior laryngeal nerve', 'electrical stimulation', 'phrenic', 'felis catus', 'tracheal pressure'], 'contributors': [{'firstName': 'Kendall', 'middleInitial': None, 'lastName': 'Morris', 'degree': None, 'orcid': '0000-0001-6582-1203'}, {'firstName': 'Kofi-Kermit', 'middleInitial': None, 'lastName': 'Horton', 'degree': None, 'orcid': None}, {'firstName': 'Lauren', 'middleInitial': None, 'lastName': 'Segers', 'degree': None, 'orcid': None}, {'firstName': 'Sarah', 'middleInitial': None, 'lastName': 'Nuding', 'degree': None, 'orcid': None}, {'firstName': 'Christian', 'middleInitial': None, 'lastName': 'Gestreau', 'degree': None, 'orcid': None}, {'firstName': 'Pierina', 'middleInitial': None, 'lastName': 'Alencar', 'degree': None, 'orcid': None}, {'firstName': 'Dale', 'middleInitial': None, 'lastName': 'Shuman', 'degree': None, 'orcid': None}, {'firstName': 'Russell', 'middleInitial': None, 'lastName': \"O'Connor\", 'degree': None, 'orcid': None}, {'firstName': 'Bruce', 'middleInitial': None, 'lastName': 'Lindsey', 'degree': None, 'orcid': None}, {'firstName': 'Donald', 'middleInitial': None, 'lastName': 'Bolser', 'degree': None, 'orcid': None}, {'firstName': 'Paul', 'middleInitial': None, 'lastName': 'Davenport', 'degree': None, 'orcid': None}, {'firstName': 'Teresa', 'middleInitial': None, 'lastName': 'Pitts', 'degree': None, 'orcid': None}], 'originatingArticleDOI': ['https://doi.org/10.3389/fphys.2018.00785'], 'protocolsDOI': []}\n",
      "{'datasetId': 58, 'version': 1, 'model': 'award', 'properties': {'description': \"ABSTRACTCardiovascular diseases such as heart failure, arrhythmias, and hypertension are leading causes of morbidityand mortality in the United States and world-wide. The autonomic nervous system plays a critical role in thepathophysiology of these diseases and neuraxial modulation provides an important avenue for therapeuticintervention. The major goal of our research team is to precisely define the cardiac neural hierarchy anddevelop circuit diagrams from the macroscopic to cellular and molecular levels and share these data on anongoing basis with the scientific community. This effort will also provide verified methods and tools forassessing neuromodulation. The research team will make them freely available to the scientific community. Amultiscale, multidisciplinary approach across various species, highly relevant to human disease, will be used todefine the anatomy of cardiac innervation in high definition. Neural structure will be linked to cardiac function.The complexity of cardiac neural control necessitates an integrative approach that will represent a tour de forcein this field. State-of-the-art anatomical, physiological, and pharmacological approaches from `cells to man'must be combined in order to achieve the above goals. This approach will be utilized at each level of theneuraxis (heart, extracardiac intrathoracic neural structures and extrathoracic neural structures). Thetechniques proposed will allow, for the first time, a detailed description of the anatomical and molecularinteractions at the synaptic and cell body levels in cardiac and extracardiac ganglia. The techniques used andthe integration of these pathways represents the most innovative attempt to understand cardiac neural controlever undertaken. Understanding these pathways has the potential to accelerate development of therapies thatwill be able to precisely target neural structures and also guide methods to re-purpose already availabletherapies (e.g. nerve stimulators) for therapeutic purposes. Ultimately, these approaches are required todevelop novel, effective, and affordable interventions for the management and prevention of heart disease andsudden cardiac death.\", 'id': '1978ac70-ff31-48bc-a2d7-772154037c12', 'principal_investigator': 'SHIVKUMAR, KALYANAM', 'title': 'COMPREHENSIVE STRUCTURAL AND FUNCTIONAL MAPPING OF THE MAMMALIAN CARDIAC NERVOUS SYSTEM', 'award_id': 'OT2OD023848'}, 'versionPublishedAt': '2020-02-28T17:59:53.465717Z', 'datasetDOI': 'https://dx.doi.org/10.26275/w4my-puqm', 'tags': ['spike recording', 'cardiac', 'nodose ganglion', 'vagal afferent neurotransmission', 'pvc', '16 channel microarray', 'coronary occlusion', 'pig'], 'contributors': [{'firstName': 'Marmar', 'middleInitial': None, 'lastName': 'Vaseghi', 'degree': 'Ph.D.', 'orcid': '0000-0002-9701-9706'}, {'firstName': 'Siamak', 'middleInitial': None, 'lastName': 'Salavtion', 'degree': None, 'orcid': None}, {'firstName': 'Naoko', 'middleInitial': None, 'lastName': 'Yamagochi', 'degree': None, 'orcid': None}, {'firstName': 'Jonathon', 'middleInitial': None, 'lastName': 'Hoang', 'degree': None, 'orcid': None}, {'firstName': 'Nicole', 'middleInitial': None, 'lastName': 'Lin', 'degree': None, 'orcid': None}, {'firstName': 'Jeffrey', 'middleInitial': None, 'lastName': 'Ardell', 'degree': 'Ph.D.', 'orcid': '0000-0001-9241-0864'}, {'firstName': 'John', 'middleInitial': None, 'lastName': 'Armour', 'degree': None, 'orcid': None}], 'originatingArticleDOI': [], 'protocolsDOI': []}\n",
      "{'datasetId': 31, 'version': 3, 'model': 'award', 'properties': {'description': '', 'id': 'f771b423-10ca-4f80-8464-9a8f39555fe6', 'principal_investigator': '', 'title': '', 'award_id': 'OT2OD024899'}, 'versionPublishedAt': '2020-02-27T00:58:02.135565Z', 'datasetDOI': 'https://dx.doi.org/10.26275/nxfv-p3ol', 'tags': ['3d imaging', 'phenotyping', 'mus muscus', 'enteric nerve system', 'rattus norvegicus', 'innervation', 'sus scrofa', 'colon'], 'contributors': [{'firstName': 'Pu-Qing', 'middleInitial': None, 'lastName': 'Yuan', 'degree': None, 'orcid': None}, {'firstName': 'Lixin', 'middleInitial': None, 'lastName': 'Wang', 'degree': None, 'orcid': None}, {'firstName': 'Million', 'middleInitial': None, 'lastName': 'Mulugeta', 'degree': None, 'orcid': None}, {'firstName': 'Yvette', 'middleInitial': None, 'lastName': 'Tache', 'degree': None, 'orcid': None}], 'originatingArticleDOI': [], 'protocolsDOI': []}\n",
      "{'datasetId': 64, 'version': 4, 'model': 'award', 'properties': {'description': 'Experiments to map physiological functions of autonomic nerves and the continued advance of bioelectronictherapies are limited by inadequate activation or block of targeted nerve fibers and unwanted co-activation orblock of non-targeted nerve fibers. More fundamentally, the relationship between applied stimuli and the nervefibers that are activated or blocked, how this relationship varies across individuals and species, and how theserelationships can be controlled remain largely unknown. We will develop, implement and validate an efficientcomputational pipeline for simulation of electrical activation and block of different nerve fiber types withinautonomic nerves. The pipeline will include segmentation of microanatomy from fixed nerve samples, three-dimensional finite-element models of electrodes positioned on nerves, and non-linear cable models of differentnerve fiber types, enabling calculation of quantitative input-output maps of activation and block of specific nervefibers. As key benchmarks of pipeline development and for the proposed analysis and design efforts, we willimplement models of the cervical (VNc) and abdominal (VNa) vagus nerves in rat, in a SPARC-identified animalmodel, and in human. The VNc is an excellent test bed as it contains a broad spectrum of nerve fiber types,there are experimental data to facilitate model validation, and there are multiple applications of VNc stimulationwhere a lack of fiber selectivity limits the therapeutic window. The VNa is an excellent complement to the cervicalVNc, as a prototypical autonomic nerve of a size comparable to many of the small autonomic nerves targetedby SPARC projects. We will use the models that emerge from the pipeline to achieve analysis and design goalsto address critical gaps identified as SPARC priorities. Specifically, we will quantify of the effects of intra-speciesdifferences in nerve morphology on activation and block by building individual sample-specific models for eachnerve and specie. These models will also be used to quantify inter-species differences in nerve fiber activationand block and to identify electrode designs and stimulation parameters that produce equivalent degrees ofactivation and block across species. We will combine the resulting models with engineering optimization todesign approaches to increase the selectivity and efficiency of activation and block of different nerve fiber types.The outcomes will be a pipeline for modeling autonomic nerves, electrode geometries, and stimulationparameters, as well as tools that address the limitations of nerve stimulation selectivity and efficiency that hinderthe continued advance of physiological mapping studies and the development of bioelectronic therapies.', 'id': 'db090035-8a57-4474-8c3d-2536dee9499f', 'principal_investigator': 'GRILL, WARREN M.', 'title': 'MODELING ACTIVATION AND BLOCK OF AUTONOMIC NERVES FOR ANALYSIS AND DESIGN', 'award_id': 'OT2OD025340'}, 'versionPublishedAt': '2020-10-01T15:41:57.651749Z', 'datasetDOI': 'https://dx.doi.org/10.26275/maq2-eii4', 'tags': ['vagus nerve stimulation', 'neural anatomy', 'vagus nerve morphology', 'autonomic nervous system'], 'contributors': [{'firstName': 'Nicole', 'middleInitial': 'A', 'lastName': 'Pelot', 'degree': 'Ph.D.', 'orcid': '0000-0003-2844-0190'}, {'firstName': 'Gabriel', 'middleInitial': 'B', 'lastName': 'Goldhagen', 'degree': None, 'orcid': None}, {'firstName': 'Jake', 'middleInitial': 'E', 'lastName': 'Cariello', 'degree': None, 'orcid': None}, {'firstName': 'Warren', 'middleInitial': 'M', 'lastName': 'Grill', 'degree': 'Ph.D.', 'orcid': '0000-0001-5240-6588'}], 'originatingArticleDOI': [], 'protocolsDOI': ['dx.doi.org/10.17504/protocols.io.6bvhan6']}\n",
      "{'datasetId': 121, 'version': 1, 'model': 'award', 'properties': {'description': '', 'id': 'a3b6cdd7-7d9e-4760-8ec5-c41a961f46d5', 'principal_investigator': '', 'title': '', 'award_id': 'OT2OD023847'}, 'versionPublishedAt': '2021-04-11T16:47:29.132201Z', 'datasetDOI': 'https://dx.doi.org/10.26275/zxe9-o3ss', 'tags': ['micro-ct', 'stomach', 'vasculature', 'rat', 'microfil mv-122'], 'contributors': [{'firstName': 'Terry', 'middleInitial': None, 'lastName': 'Powley', 'degree': None, 'orcid': '0000-0001-6689-7058'}, {'firstName': 'Deborah', 'middleInitial': None, 'lastName': 'Jaffey', 'degree': None, 'orcid': None}, {'firstName': 'Logan', 'middleInitial': None, 'lastName': 'Chesney', 'degree': None, 'orcid': None}, {'firstName': 'Jennifer', 'middleInitial': None, 'lastName': 'McAdams', 'degree': None, 'orcid': None}, {'firstName': 'Bartek', 'middleInitial': None, 'lastName': 'Rajwa', 'degree': None, 'orcid': '0000-0001-7540-8236'}], 'originatingArticleDOI': [], 'protocolsDOI': ['dx.doi.org/10.17504/protocols.io.bafnibme']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#change loop variant on prod\n",
    "# loop_variant = list_of_datasets[:2]\n",
    "loop_variant = list_of_datasets[:5]\n",
    "\n",
    "for item in tqdm(loop_variant):\n",
    "    url = \"https://api.pennsieve.io/zipit/discover\"    \n",
    "    payload = {\"data\": {\n",
    "        \"paths\": [\"files/dataset_description.xlsx\"],\n",
    "        \"version\": item['version'],\n",
    "        \"datasetId\": item['datasetId']\n",
    "    }}\n",
    "    response = requests.request(\"POST\", url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    local_filename = \"dataset_description.xlsx\"\n",
    "    totalbits = 0\n",
    "    if response.status_code == 200:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    totalbits += 1024\n",
    "#                     print(\"Downloaded\",totalbits*1025,\"KB...\")\n",
    "                    f.write(chunk)\n",
    "        try: \n",
    "            xl = pd.ExcelFile(\"dataset_description.xlsx\")\n",
    "            df = xl.parse(\"Sheet1\")\n",
    "\n",
    "            # arrays to hold dois for each dataset\n",
    "            originating_article_array = []\n",
    "            protocol_array = []\n",
    "\n",
    "            # get all dois from dataframe\n",
    "            for index, row in df.iterrows():\n",
    "                row_val = row['Metadata element']\n",
    "                if (row_val.find('Originating Article') != -1):\n",
    "                    count = 0\n",
    "                    for col_val in row:\n",
    "                        if (count > 2):\n",
    "                            try: \n",
    "                                if col_val.find('doi.org') != -1:\n",
    "                                    pos = col_val.find('http')\n",
    "                                    if pos != -1:\n",
    "                                        col_val = col_val[pos:]\n",
    "                                    originating_article_array.append(col_val)\n",
    "                            except:\n",
    "                                pass\n",
    "                        count = count + 1\n",
    "                if (row_val.find('Protocol') != -1):\n",
    "                    count = 0\n",
    "                    for col_val in row:\n",
    "                        if (count > 2):\n",
    "                            try: \n",
    "                                if (col_val.find('doi.org') != -1):\n",
    "                                    pos = col_val.find('http')\n",
    "                                    if pos != -1:\n",
    "                                        col_val = col_val[pos:]\n",
    "                                    protocol_array.append(col_val)\n",
    "                            except:\n",
    "                                pass\n",
    "                        count = count + 1\n",
    "            item[\"originatingArticleDOI\"] = originating_article_array\n",
    "            item[\"protocolsDOI\"] = protocol_array\n",
    "        except: \n",
    "            print(item)\n",
    "            item[\"originatingArticleDOI\"] = []\n",
    "            item[\"protocolsDOI\"] = []\n",
    "\n",
    "for item in loop_variant:\n",
    "    print( item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83fdd7e9-a8c1-42c9-8073-0a31511b7579",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 4 [] ['dx.doi.org/10.17504/protocols.io.6bvhan6']\n",
      "121 1 [] ['dx.doi.org/10.17504/protocols.io.bafnibme']\n",
      "24 2 ['https://doi.org/10.1111/nmo.13380'] []\n",
      "31 3 [] []\n",
      "54 1 [] ['https://dx.doi.org/10.17504/protocols.io.wqmfdu6']\n",
      "65 6 [] ['dx.doi.org/10.17504/protocols.io.bh4dj8s6']\n",
      "27 2 [] []\n",
      "35 3 ['https://doi.org/10.3389/fphys.2018.00785'] []\n",
      "58 1 [] []\n",
      "55 1 [] []\n",
      "127 1 [] []\n",
      "137 1 [] []\n",
      "103 4 [] []\n",
      "63 2 ['https://doi.org/10.1371/journal.pcbi.1002061'] []\n",
      "23 2 [] ['dx.doi.org/10.17504/protocols.io.5nkg5cw']\n",
      "43 5 [] ['https://dx.doi.org/10.17504/protocols.io.9gbh3sn', 'https://dx.doi.org/10.17504/protocols.io.y3tfynn', 'https://dx.doi.org/10.17504/protocols.io.bjfzkjp6']\n",
      "29 6 [] []\n",
      "119 1 [] []\n",
      "56 1 [] ['https://dx.doi.org/10.17504/protocols.io.wjrfcm6']\n",
      "76 3 [] []\n",
      "10 3 [] []\n",
      "59 1 ['https://doi.org/10.1007/s00441-018-2957-0'] []\n",
      "97 1 ['https://doi.org/10.1088/1741-2552/ab7ad4'] []\n",
      "123 1 [] ['https://doi.org/10.17504/protocols.io.2irgcd6']\n",
      "130 1 ['https://doi.org/10.1038/s41598-021-81822-3'] ['dx.doi.org/10.17504/protocols.io.w6hfhb6']\n",
      "117 1 [] []\n",
      "135 1 ['https://doi.org/10.1113/jp273259'] []\n",
      "34 3 [] ['dx.doi.org/10.17504/protocols.io.3rmgm46']\n",
      "150 1 ['https://doi.org/10.1111/nmo.13925'] ['dx.doi.org/10.17504/protocols.io.3rmgm46']\n",
      "100 4 [] []\n",
      "114 1 [] ['dx.doi.org/10.17504/protocols.io.bfxbjpin', 'dx.doi.org/10.17504/protocols.io.bfxgjpjw']\n",
      "158 1 [] ['dx.doi.org/10.17504/protocols.io.bqavmse6']\n",
      "159 1 [] ['dx.doi.org/10.17504/protocols.io.ba8hiht6']\n",
      "116 1 [] []\n",
      "20 3 ['https://doi.org/10.1007/s00441-019-03029-3'] []\n",
      "48 1 ['https://doi.org/10.1038/s41598-017-10639-w'] []\n",
      "118 1 [] []\n",
      "49 1 [] []\n",
      "61 3 [] ['dx.doi.org/10.17504/protocols.io.bh4cj8sw']\n",
      "107 1 [] []\n",
      "50 1 [] []\n",
      "77 2 [] ['dx.doi.org/10.17504/protocols.io.bdz5i786']\n",
      "74 2 [] []\n",
      "57 1 [] []\n",
      "28 2 [] []\n",
      "11 3 [] []\n",
      "105 2 [] []\n",
      "133 1 [] ['dx.doi.org/10.17504/protocols.io.bh3tj8nn']\n",
      "126 1 [] ['dx.doi.org/10.17504/protocols.io.82fhybn']\n",
      "149 1 ['https://doi.org/10.1111/nmo.13925'] ['dx.doi.org/10.17504/protocols.io.3rmgm46']\n",
      "153 1 [] []\n",
      "86 3 ['https://doi.org/10.1152/jn.00315.2020'] []\n",
      "106 1 [] ['dx.doi.org/10.17504/protocols.io.w3gfgjw']\n",
      "120 1 [] ['dx.doi.org/10.17504/protocols.io.bf2pjqdn', 'dx.doi.org/10.17504/protocols.io.bf2kjqcw']\n",
      "88 1 ['https://doi.org/10.1002/cne.24949'] ['https://dx.doi.org/10.17504/protocols.io.bakxicxn']\n",
      "62 1 ['https://doi.org/10.1088/1741-2552/aad78e'] ['dx.doi.org/10.17504/protocols.io.ww7ffhn']\n",
      "108 1 ['https://doi.org/10.1101/2020.07.06.189696'] []\n",
      "60 4 [] ['dx.doi.org/10.17504/protocols.io.y6hfzb6']\n",
      "44 2 [] []\n",
      "82 1 [] ['dx.doi.org/10.17504/protocols.io.6bqhamw']\n",
      "115 1 [] []\n",
      "128 1 [] []\n",
      "131 1 [] ['dx.doi.org/10.17504/protocols.io.98uh9ww', 'dx.doi.org/10.17504/protocols.io.baagiabw']\n",
      "139 1 ['https://doi.org/10.1038/s41598-018-26651-7'] ['https://doi.org/10.1038/s41598-018-26651-7']\n",
      "138 1 [] []\n",
      "140 1 [] ['dx.doi.org/10.17504/protocols.io.babtiann']\n",
      "94 2 [] []\n",
      "124 2 ['https://doi.org/10.1038/s41598-020-70216-6'] ['dx.doi.org/10.17504/protocols.io.bpcamise']\n",
      "101 4 [] []\n",
      "152 1 [] []\n",
      "102 3 [] []\n",
      "99 4 [] []\n",
      "160 1 [] ['dx.doi.org/10.17504/protocols.io.bgdmjs46']\n",
      "85 1 ['https://doi.org/10.1088/1741-2552/ab7ad4'] ['dx.doi.org/10.17504/protocols.io.9ieh4be']\n",
      "90 1 [] ['dx.doi.org/10.17504/protocols.io.xpxfmpn']\n",
      "51 1 [] []\n",
      "32 3 [] ['dx.doi.org/10.17504/protocols.io.x3sfqne']\n",
      "52 1 [] []\n",
      "75 1 [] []\n",
      "41 2 ['https://doi.org/10.1371/journal.pone.0223279'] ['dx.doi.org/10.17504/protocols.io.6a8hahw', 'dx.doi.org/10.17504/protocols.io.6crhav6', 'dx.doi.org/10.17504/protocols.io.6a7hahn']\n",
      "36 4 ['https://doi.org/10.1152/ajpgi.00252.2018'] ['dx.doi.org/10.17504/protocols.io.xz6fp9e ']\n",
      "33 2 [] []\n",
      "109 2 ['https://doi.org/10.1101/2020.09.18.303958'] ['dx.doi.org/10.17504/protocols.io.bqu2mwye']\n",
      "21 2 [] []\n",
      "68 1 [] []\n",
      "26 3 [] []\n",
      "9 4 [] []\n",
      "37 2 ['https://doi.org/10.1016/j.isci.2020.101140'] ['dx.doi.org/10.17504/protocols.io.bdz5i786']\n",
      "16 5 [] ['dx.doi.org/10.17504/protocols.io.bh4bj8sn']\n",
      "12 3 [] []\n",
      "73 1 [] []\n",
      "137 1 [] []\n",
      "125 1 ['https://doi.org/10.1111/nmo.13685'] []\n",
      "143 1 [] ['https://dx.doi.org/10.17504/protocols.io.wwbffan']\n",
      "104 2 [] []\n",
      "151 1 [] ['dx.doi.org/10.17504/protocols.io.bgfzjtp6']\n",
      "132 1 [] ['dx.doi.org/10.17504/protocols.io.bf2pjqdn', 'dx.doi.org/10.17504/protocols.io.bf2kjqcw']\n",
      "98 3 [] []\n"
     ]
    }
   ],
   "source": [
    "for item in loop_variant:\n",
    "    print(item[\"datasetId\"], item[\"version\"], item[\"originatingArticleDOI\"],  item[\"protocolsDOI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5946d54-d659-48f1-adfa-42478b424a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb3fd63-d6a0-466f-b9b0-ce1bf07d76e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef6a59-2f76-4ca0-882b-37d23030f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import requests\n",
    "import pandas as pd \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038578c-4d64-4764-9c27-bfd5729f3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_datasets_with_metadata(list_of_datasets):\n",
    "    \n",
    "    # get list of datasets with awards associated with it\n",
    "    url = \"https://api.pennsieve.io/discover/search/records\"\n",
    "    querystring = {\"model\": \"award\"}\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    #test request to find out how many total datsets are present\n",
    "    response = requests.request(\n",
    "        \"GET\", url, headers=headers, params=querystring)\n",
    "    response.raise_for_status()\n",
    "    response = response.json()\n",
    "\n",
    "    # get all\n",
    "    querystring = {\"limit\": response[\"totalCount\"], \"model\": \"award\"}\n",
    "    response = requests.request(\n",
    "        \"GET\", url, headers=headers, params=querystring)\n",
    "    response.raise_for_status()\n",
    "    response = response.json()\n",
    "    list_of_datasets = response[\"records\"].copy()\n",
    "\n",
    "    url = \"\"\n",
    "    querystring = \"\"\n",
    "    headers = \"\"\n",
    "    response = \"\"\n",
    "\n",
    "    # get latest version of each dataset\n",
    "    for item in tqdm(list_of_datasets):\n",
    "        url = f\"https://api.pennsieve.io/discover/datasets/{item['datasetId']}\"\n",
    "        headers = {\"Accept\": \"application/json\"}\n",
    "        response = requests.request(\"GET\", url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        response = response.json()\n",
    "        item['name'] = response['name']\n",
    "        item['description'] = response['description']\n",
    "        item['version'] = response['version']\n",
    "        item['versionPublishedAt'] = response['versionPublishedAt']\n",
    "        item['datasetDOI'] = 'https://dx.doi.org/' + response['doi']\n",
    "        item['tags'] = response['tags']\n",
    "        item['contributors'] = response['contributors']\n",
    "\n",
    "    # extract metadata information\n",
    "    for item in tqdm(list_of_datasets):\n",
    "        # get the actual dataset_description.xlsx file.\n",
    "        # seems to be the best way for pandas to read\n",
    "        url = \"https://api.pennsieve.io/zipit/discover\"\n",
    "        payload = {\"data\": {\n",
    "            \"paths\": [\"files/dataset_description.xlsx\"],\n",
    "            \"version\": item['version'],\n",
    "            \"datasetId\": item['datasetId']\n",
    "        }}\n",
    "        response = requests.request(\"POST\", url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        local_filename = \"dataset_description.xlsx\"\n",
    "        totalbits = 0\n",
    "\n",
    "        # write binary data to a file that is readable in pandas\n",
    "        if response.status_code == 200:\n",
    "            with open(local_filename, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        totalbits += 1024\n",
    "                        # print(\"Downloaded\",totalbits*1025,\"KB...\")\n",
    "                        f.write(chunk)\n",
    "\n",
    "            # only reading through xlsx files at the moment.\n",
    "            # could be extended for json and csv (rare instances by SPARC curation standards) if time permits\n",
    "            try:\n",
    "                xl = pd.ExcelFile(\"dataset_description.xlsx\")\n",
    "                df = xl.parse(\"Sheet1\")\n",
    "\n",
    "                # arrays to hold dois for each dataset\n",
    "                originating_article_array = []\n",
    "                protocol_array = []\n",
    "\n",
    "                # get all dois from dataframe\n",
    "                for index, row in df.iterrows():\n",
    "                    row_val = row['Metadata element']\n",
    "                    if (row_val.find('Originating Article') != -1):\n",
    "                        count = 0\n",
    "                        for col_val in row:\n",
    "                            if (count > 2):\n",
    "                                try:\n",
    "                                    if col_val.find('doi.org') != -1:\n",
    "                                        pos = col_val.find('http')\n",
    "                                        if pos != -1:\n",
    "                                            col_val = col_val[pos:]\n",
    "                                        originating_article_array.append(\n",
    "                                            col_val)\n",
    "                                except:\n",
    "                                    pass\n",
    "                            count = count + 1\n",
    "                    if (row_val.find('Protocol') != -1):\n",
    "                        count = 0\n",
    "                        for col_val in row:\n",
    "                            if (count > 2):\n",
    "                                try:\n",
    "                                    if (col_val.find('doi.org') != -1):\n",
    "                                        pos = col_val.find('http')\n",
    "                                        if pos != -1:\n",
    "                                            col_val = col_val[pos:]\n",
    "                                        protocol_array.append(col_val)\n",
    "                                except:\n",
    "                                    pass\n",
    "                            count = count + 1\n",
    "                item[\"originatingArticleDOI\"] = originating_article_array\n",
    "                item[\"protocolsDOI\"] = protocol_array\n",
    "            except:\n",
    "                # for any xlsx files that are corrupted or cannot be read, ignore\n",
    "                item[\"originatingArticleDOI\"] = []\n",
    "                item[\"protocolsDOI\"] = []\n",
    "\n",
    "    return list_of_datasets\n",
    "\n",
    "datset_list = []\n",
    "datset_list = get_list_of_datasets_with_metadata(list_of_datasets)\n",
    "print(datset_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
